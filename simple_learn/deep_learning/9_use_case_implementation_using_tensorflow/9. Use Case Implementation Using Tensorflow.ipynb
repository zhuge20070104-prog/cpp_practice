{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 使用个体的不同特征来预测他的收入\n",
    "# tf.estimator.LinearClassifier 是 TensorFlow 中的一个预创建的 Estimator，用于构建线性分类器模型。它是一个高级别的 API，可以简化模型的构建、训练和评估过程。\n",
    "\n",
    "# 读取数据\n",
    "\n",
    "import pandas as pd \n",
    "census = pd.read_csv(\"./census_data.csv\")\n",
    "# display the header of the data\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换label为数字，train_test_split\n",
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test_split on the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_data = census.drop('income_bracket', axis=1)\n",
    "y_labels = census['income_bracket']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为分类值和连续值创建feature_column\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Create the feature columns for the categorical values using vocabulary lists or hash buckets\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list('gender', ['Female', 'Male'])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=1000)\n",
    "maritial_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship', hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature columns for the continuous values using numeric_column\n",
    "\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpk8ucl9b6\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpk8ucl9b6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# 这里绑定的pandas input fn\n",
    "# Put all these variables into a single list with the variable name feat_cols\n",
    "feat_cols = [gender, occupation, maritial_status, relationship, education, workclass, native_country,\n",
    "            age, education_num, capital_gain, capital_loss, hours_per_week]\n",
    "\n",
    "# Create the input func, batch size is up to you\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=x_train, y=y_train, batch_size=128, num_epochs=None, shuffle=True)\n",
    "\n",
    "# Create the model with tf.estimator using LinearClassifier\n",
    "\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpk8ucl9b6/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20000...\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /tmp/tmpk8ucl9b6/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20000...\n",
      "INFO:tensorflow:loss = 47.943413, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 236.079\n",
      "INFO:tensorflow:loss = 34.600403, step = 20101 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.943\n",
      "INFO:tensorflow:loss = 29.83136, step = 20201 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.758\n",
      "INFO:tensorflow:loss = 22.175354, step = 20301 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.647\n",
      "INFO:tensorflow:loss = 51.4638, step = 20401 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.231\n",
      "INFO:tensorflow:loss = 46.324955, step = 20501 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.793\n",
      "INFO:tensorflow:loss = 42.38406, step = 20601 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.539\n",
      "INFO:tensorflow:loss = 37.349823, step = 20701 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.205\n",
      "INFO:tensorflow:loss = 39.897552, step = 20801 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.927\n",
      "INFO:tensorflow:loss = 281.18457, step = 20901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.63\n",
      "INFO:tensorflow:loss = 61.96653, step = 21001 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.192\n",
      "INFO:tensorflow:loss = 30.968962, step = 21101 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.25\n",
      "INFO:tensorflow:loss = 66.25371, step = 21201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.188\n",
      "INFO:tensorflow:loss = 50.19114, step = 21301 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.683\n",
      "INFO:tensorflow:loss = 46.734394, step = 21401 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.327\n",
      "INFO:tensorflow:loss = 37.975075, step = 21501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.812\n",
      "INFO:tensorflow:loss = 34.757786, step = 21601 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.2\n",
      "INFO:tensorflow:loss = 50.683556, step = 21701 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.76\n",
      "INFO:tensorflow:loss = 125.05054, step = 21801 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.839\n",
      "INFO:tensorflow:loss = 40.505287, step = 21901 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.173\n",
      "INFO:tensorflow:loss = 38.99186, step = 22001 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.56\n",
      "INFO:tensorflow:loss = 92.00801, step = 22101 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.592\n",
      "INFO:tensorflow:loss = 46.323036, step = 22201 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.655\n",
      "INFO:tensorflow:loss = 76.02666, step = 22301 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.092\n",
      "INFO:tensorflow:loss = 46.35009, step = 22401 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.547\n",
      "INFO:tensorflow:loss = 51.695667, step = 22501 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.065\n",
      "INFO:tensorflow:loss = 42.361355, step = 22601 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.929\n",
      "INFO:tensorflow:loss = 34.449997, step = 22701 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.759\n",
      "INFO:tensorflow:loss = 38.740356, step = 22801 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.727\n",
      "INFO:tensorflow:loss = 203.36902, step = 22901 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.82\n",
      "INFO:tensorflow:loss = 44.044506, step = 23001 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.983\n",
      "INFO:tensorflow:loss = 57.516678, step = 23101 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.944\n",
      "INFO:tensorflow:loss = 45.99482, step = 23201 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.113\n",
      "INFO:tensorflow:loss = 233.27701, step = 23301 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.687\n",
      "INFO:tensorflow:loss = 33.859737, step = 23401 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.274\n",
      "INFO:tensorflow:loss = 44.678726, step = 23501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.563\n",
      "INFO:tensorflow:loss = 46.221146, step = 23601 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.963\n",
      "INFO:tensorflow:loss = 57.50306, step = 23701 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.556\n",
      "INFO:tensorflow:loss = 94.25842, step = 23801 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.552\n",
      "INFO:tensorflow:loss = 150.5882, step = 23901 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.569\n",
      "INFO:tensorflow:loss = 36.91307, step = 24001 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.207\n",
      "INFO:tensorflow:loss = 55.127174, step = 24101 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.498\n",
      "INFO:tensorflow:loss = 48.64279, step = 24201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.359\n",
      "INFO:tensorflow:loss = 100.22506, step = 24301 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.59\n",
      "INFO:tensorflow:loss = 35.77504, step = 24401 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.948\n",
      "INFO:tensorflow:loss = 54.321068, step = 24501 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.207\n",
      "INFO:tensorflow:loss = 77.93094, step = 24601 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.489\n",
      "INFO:tensorflow:loss = 40.29514, step = 24701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.685\n",
      "INFO:tensorflow:loss = 41.40147, step = 24801 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.441\n",
      "INFO:tensorflow:loss = 53.677483, step = 24901 (0.306 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 25000...\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tmpk8ucl9b6/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 25000...\n",
      "INFO:tensorflow:Loss for final step: 33.12332.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x7f0bef8b6588>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for at least 5000 steps\n",
    "model.train(input_fn=input_func, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs过几遍数据，\n",
    "# 如果总共有1000个数据，那么一个epoch就是10个batch\n",
    "# 3个epoch就是30个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpk8ucl9b6/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the models\n",
    "\n",
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=x_test, batch_size=len(x_test), shuffle=False)\n",
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22357    0\n",
       "26009    0\n",
       "20734    0\n",
       "17695    0\n",
       "27908    1\n",
       "27225    0\n",
       "13108    0\n",
       "27552    0\n",
       "14043    0\n",
       "30313    0\n",
       "Name: income_bracket, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logits': array([-0.72672707], dtype=float32),\n",
       "  'logistic': array([0.32591337], dtype=float32),\n",
       "  'probabilities': array([0.67408663, 0.32591337], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-7.4326153], dtype=float32),\n",
       "  'logistic': array([0.00059137], dtype=float32),\n",
       "  'probabilities': array([9.994087e-01, 5.912884e-04], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-0.35155025], dtype=float32),\n",
       "  'logistic': array([0.41300654], dtype=float32),\n",
       "  'probabilities': array([0.5869934, 0.4130065], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-8.948896], dtype=float32),\n",
       "  'logistic': array([0.00012991], dtype=float32),\n",
       "  'probabilities': array([9.9987006e-01, 1.2986353e-04], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-0.17913264], dtype=float32),\n",
       "  'logistic': array([0.4553362], dtype=float32),\n",
       "  'probabilities': array([0.5446638, 0.4553362], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-3.7814074], dtype=float32),\n",
       "  'logistic': array([0.02228275], dtype=float32),\n",
       "  'probabilities': array([0.9777173 , 0.02228276], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-5.233476], dtype=float32),\n",
       "  'logistic': array([0.00530666], dtype=float32),\n",
       "  'probabilities': array([0.99469334, 0.00530664], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-3.8246222], dtype=float32),\n",
       "  'logistic': array([0.02136046], dtype=float32),\n",
       "  'probabilities': array([0.9786396 , 0.02136046], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-5.6856694], dtype=float32),\n",
       "  'logistic': array([0.0033828], dtype=float32),\n",
       "  'probabilities': array([0.99661726, 0.00338278], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)},\n",
       " {'logits': array([-2.166437], dtype=float32),\n",
       "  'logistic': array([0.1028052], dtype=float32),\n",
       "  'probabilities': array([0.8971948 , 0.10280522], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'all_class_ids': array([0, 1], dtype=int32),\n",
       "  'all_classes': array([b'0', b'1'], dtype=object)}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = list()\n",
    "for pred in predictions:\n",
    "    final_preds.append(int(pred['class_ids'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      7436\n",
      "           1       0.73      0.56      0.64      2333\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.80      0.75      0.77      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate models performance on test data\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, final_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
